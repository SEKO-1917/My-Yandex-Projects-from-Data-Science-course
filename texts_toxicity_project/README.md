## Описание проекта

Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

### Задача 

Обучить модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Построить модель со значением метрики качества F1 не меньше 0.75. 

## Используемые библиотеки
*python*, *pandas*, *numpy*, *nltk*, *sklearn*, *CatBoost*

# Вывод

Проанализировали данные:
- обнаружили и удалили дисбаланс классов 
- визулизировали часто употребляемые слова в токсичных и нетоксичных комментариях с помощью облака слов

Предобработали данные:
- очистили текст от неалфавитных символов
- токенизировали
- лемматизировали
- удалили стоп-слова

Обучили разные модели и получили наилучшую:
```python
LogisticRegression(C=2, penalty='l1', random_state=77,
                                    solver='liblinear'))])
```
Метрика (f1) лучшей модели на кросс-валидации: 0.783
На тесте: 0.79
